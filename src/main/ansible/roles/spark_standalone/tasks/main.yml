---
- name: Download Spark pre-built package
  get_url: url={{ spark_download_url }} dest="/tmp/spark-{{ spark_version }}.tgz"
  tags:
    - install

- name: Extract Spark archive
  unarchive: copy=no src="/tmp/spark-{{ spark_version }}.tgz" dest=/opt/
  sudo_user: "{{ clusteruser }}"
  tags:
    - install

- name: Create link to Spark directory
  file: src=/opt/spark-{{ spark_version }} dest={{ spark_root }} state=link
  tags:
    - install

- include_vars: roles/hadoop_common/vars/main.yml
  tags:
    - configure

- name: Configure Spark to run in standalone deploy mode
  template: src=conf/spark-env.sh.j2 dest={{ spark_root }}/conf/spark-env.sh
  tags:
    - configure

- name: populate conf/slaves file
  template: src=conf/slaves.j2 dest={{ spark_root }}/conf/slaves
  tags:
    - configure

- name: increase default spark.executor.memory parameter
  template: src=conf/spark-defaults.conf.j2 dest={{ spark_root }}/conf/spark-defaults.conf
  tags:
    - configure

#
# This needs to happen on a user who's key is present on all spark hosts. Currently, this is {{ clusteruser }} 
#
- name: Attempt to start Spark cluster  
  shell: "{{ spark_root }}/sbin/start-all.sh"
  sudo_user: "{{ clusteruser }}"
  when: ansible_hostname == "{{ spark_master_host }}"
  ignore_errors: true
  tags:
    - configure

